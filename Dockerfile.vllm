# GPU image with vLLM backend for DeepSeek-OCR
# Use CUDA 12.1 + cuDNN runtime from NVIDIA base (verified available on Docker Hub)
ARG BASE_IMAGE=nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04
FROM ${BASE_IMAGE}

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv \
    build-essential \
    git \
    libglib2.0-0 libgl1 \
    && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --upgrade pip

WORKDIR /srv/app

COPY requirements.txt ./
# Install vLLM first (it brings torch, transformers, tokenizers, pydantic, etc.)
# Then install only missing app-specific deps to avoid conflicts
RUN python3 -m pip install --no-cache-dir vllm --pre --extra-index-url https://wheels.vllm.ai/nightly && \
    grep -v '^torch' requirements.txt | grep -v '^transformers' | grep -v '^tokenizers' | \
    grep -v '^pydantic' | grep -v '^numpy' > req.txt && \
    python3 -m pip install --no-cache-dir -r req.txt && \
    rm req.txt && \
    apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* ~/.cache/pip

COPY app ./app
COPY web ./web

ENV APP_BACKEND=vllm \
    APP_FORCE_CPU=false

EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
